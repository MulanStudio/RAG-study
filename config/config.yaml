# =====================================================
# ğŸ›¢ï¸ æ²¹ç”°æœåŠ¡ RAG ç³»ç»Ÿ - ç»Ÿä¸€é…ç½®æ–‡ä»¶
# =====================================================
# ä½¿ç”¨æ–¹æ³•ï¼šä¿®æ”¹æ­¤æ–‡ä»¶å³å¯è°ƒæ•´ç³»ç»Ÿè¡Œä¸ºï¼Œæ— éœ€æ”¹ä»£ç 

# -----------------------------------------------------
# ğŸ“‚ æ•°æ®è·¯å¾„é…ç½®
# -----------------------------------------------------
data:
  # æ•°æ®æ ¹ç›®å½•ï¼ˆæŠŠç»„å§”ä¼šçš„æ•°æ®æ”¾è¿™é‡Œï¼‰
  root_dir: "data/"
  
  # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
  supported_formats:
    documents: ["pdf", "docx", "xlsx", "csv", "md", "pptx"]
    images: ["png", "jpg", "jpeg"]
    videos: ["mp4"]  # æš‚ä¸æ”¯æŒ

# -----------------------------------------------------
# ğŸ¤– æ¨¡å‹é…ç½®
# -----------------------------------------------------
models:
  # LLM é…ç½® (æœ¬åœ° Ollama)
  llm:
    provider: "azure_openai"
    model_name: "gpt-5-chat"
    base_url: ""
    temperature: 0.1  # ä½æ¸©åº¦ = æ›´ç¡®å®šæ€§çš„å›ç­”
  
  # VLM é…ç½® (å›¾ç‰‡ç†è§£)
  vlm:
    enabled: true
    model_name: "llava"
    base_url: "http://127.0.0.1:11434"
  
  # Embedding æ¨¡å‹
  # å¯é€‰ provider: "azure_openai", "huggingface", "huggingface_local"
  embedding:
    provider: "azure_openai"
    model_name: "text-embedding-3-large"
    # æœ¬åœ° GPU æ¨¡å‹é…ç½®ï¼ˆprovider: "huggingface_local" æ—¶ä½¿ç”¨ï¼‰
    # model_name: "BAAI/bge-large-en-v1.5"
    # device: "cuda"  # æˆ– "cpu"

  # Azure OpenAI é…ç½®
  azure_openai:
    team_domain: ""  # ä¾‹å¦‚: your-team-name
    api_key_env: "AZURE_OPENAI_API_KEY"
    completion_model: "gpt-5-chat"
    completion_model_fallback: "gpt-5-mini"
    embedding_model: "text-embedding-3-large"
  
  # Reranker æ¨¡å‹
  reranker:
    # è‹±æ–‡è¯­æ–™ä¼˜å…ˆï¼ˆè½»é‡çº§ Cross-Encoderï¼‰
    model_name: "cross-encoder/ms-marco-MiniLM-L-6-v2"

# -----------------------------------------------------
# ğŸ“‘ æ–‡æ¡£å¤„ç†é…ç½®
# -----------------------------------------------------
indexing:
  # Parent-Child åˆ†å—ç­–ç•¥ï¼ˆé»˜è®¤é…ç½®ï¼‰
  chunk_size_parent: 2000    # çˆ¶å—å¤§å°ï¼ˆç”¨äºç”Ÿæˆï¼‰
  chunk_overlap_parent: 200
  chunk_size_child: 400      # å­å—å¤§å°ï¼ˆç”¨äºæ£€ç´¢ï¼‰
  chunk_overlap_child: 50

# æ¯”èµ›ä¼˜åŒ–é…ç½®ï¼ˆå¤§æ•°æ®é‡æ—¶ä½¿ç”¨ï¼Œå‡å°‘ chunk æ•°é‡ï¼‰
indexing_competition:
  chunk_size_parent: 3000
  chunk_overlap_parent: 300
  chunk_size_child: 600
  chunk_overlap_child: 80

# -----------------------------------------------------
# ğŸ” æ£€ç´¢é…ç½®
# -----------------------------------------------------
retrieval:
  # åˆ†ç»„å¬å› Top-K
  k_excel: 10      # Excel/CSV æ•°æ®
  k_word: 5        # Word åˆåŒ
  k_image: 3       # å›¾ç‰‡æè¿°
  k_tech: 5        # æŠ€æœ¯æ–‡æ¡£ï¼ˆMarkdownï¼‰
  k_pdf_table: 6   # PDF è¡¨æ ¼è®°å½•
  k_pdf_text: 5    # PDF æ–‡æœ¬
  k_ppt: 5         # PPT å¹»ç¯ç‰‡
  k_general: 5     # é€šç”¨
  
  # è´¢åŠ¡é—®é¢˜åŠ¨æ€åŠ æƒ
  k_financial_boost: 15
  
  # RRF èåˆå‚æ•°
  rrf:
    k: 60          # RRF å¸¸æ•°
    weights:
      vector: 1.0
      bm25: 0.8
      hyde: 1.2
  
  # HyDE é…ç½®
  hyde:
    enabled: true

# -----------------------------------------------------
# ğŸ“ Prompt æ¨¡æ¿
# -----------------------------------------------------
prompts:
  # é—®é¢˜æ”¹å†™ (CRAG)
  rewrite: |
    You are a question re-writer that converts an input question to a better version optimized for vectorstore retrieval.
    Input Question: {original_query}
    Output ONLY the improved question. No other text.

  # æ–‡æ¡£è´¨é‡è¯„ä¼° (CRAG)
  grade: |
    You are a grader assessing relevance of a retrieved document to a user question.
    Question: {query}
    Document: {doc_content}
    Give a binary score 'yes' or 'no'. Output only 'yes' or 'no'.

  # ç­”æ¡ˆå¯ä¿¡æ€§æ ¡éªŒ (Guard)
  faithfulness_check: |
    You are a strict fact-checker.
    Question: {query}
    Answer: {answer}
    Context: {context}
    Is the answer fully supported by the context? Answer only 'yes' or 'no'.

  # æœ€ç»ˆå›ç­”ç”Ÿæˆï¼ˆå¸¦ Few-Shot ç¤ºä¾‹ï¼‰
  generation: |
    You are a Senior Technical Expert in the Oil & Gas industry.
    Answer the user's question directly and accurately based on the Context provided.
    
    CRITICAL INSTRUCTIONS:
    1. Answer in the SAME LANGUAGE as the question (ä¸­æ–‡é—®é¢˜ç”¨ä¸­æ–‡å›ç­”).
    2. Do NOT include citations or source-referencing language.
    3. If you cannot find the answer, respond in the same language:
       - English: "I don't know."
       - ä¸­æ–‡: "ä¸çŸ¥é“ã€‚"
    4. Keep your answer concise and direct.
    5. For numerical values, include units (e.g., "33.1 Billion USD", "18%", "1500 m").
    
    EXAMPLES:
    Q: What is SLB's 2023 revenue?
    A: SLB: 33.1 Billion USD
    
    Q: Which region has the highest Q3 2024 revenue?
    A: Middle East: 850.5 Million USD
    
    Q: What is the average porosity of Zone_A?
    A: 18%
    
    Q: ä¸­æµ·æ²¹2023å¹´å‡€åˆ©æ¶¦æ˜¯å¤šå°‘ï¼Ÿ
    A: 121.6 äº¿ç¾å…ƒ
    
    Context:
    {context}
    
    User Question: {query}
    
    Answer:

  # é€‰æ‹©é¢˜å›ç­”
  choice_answer: |
    You are answering a multiple-choice question.
    Answer format must be: "<OptionLetter>. <OptionText>".
    No explanation.
    
    Context:
    {context}
    
    Question:
    {query}
    
    Answer:

  # æ¯”è¾ƒç±»é—®é¢˜èšåˆ
  aggregation_compare: |
    Based on the retrieved information, provide a comparative analysis.
    
    Sub-questions and contexts:
    {sub_results}
    
    Original Question: {original_query}
    
    Instructions:
    1. Clearly state the values for each item being compared
    2. Use specific numbers from the context
    3. Highlight key differences
    
    Answer:

  # ç½®ä¿¡åº¦åˆ¤æ–­
  confidence_check: |
    Based on the following context, can you answer the question?
    
    Context:
    {context}
    
    Question: {query}
    
    Instructions:
    - Reply with ONLY a number between 0.0 and 1.0 indicating your confidence.
    - 0.0 = The context contains NO relevant information to answer the question.
    - 0.5 = The context contains SOME related information but not enough for a definitive answer.
    - 1.0 = The context contains ALL necessary information to answer the question with certainty.
    
    Confidence (0.0-1.0):

# -----------------------------------------------------
# ğŸ“Š è¯„æµ‹é…ç½®
# -----------------------------------------------------
evaluation:
  # è¯„æµ‹æ¨¡å¼
  use_llm_judge: true  # ä½¿ç”¨ LLM ä½œä¸ºè¯„åˆ¤
  
  # é€šè¿‡é˜ˆå€¼
  pass_threshold: 7    # æ»¡åˆ† 10 åˆ†ï¼Œ7 åˆ†åŠæ ¼

# -----------------------------------------------------
# ğŸ“¥ æ‰¹é‡é—®ç­”ï¼ˆExcelï¼‰
# -----------------------------------------------------
batch_answer:
  # è¾“å…¥/è¾“å‡º Excel è·¯å¾„ï¼ˆå¯ä»¥åœ¨å‘½ä»¤è¡Œè¦†ç›–ï¼‰
  input_path: "data/questions.xlsx"
  output_path: ""  # ç•™ç©ºåˆ™è¦†ç›–è¾“å…¥æ–‡ä»¶
  question_col: "question"
  answer_col: "answer"
  start_row: 0
  limit: null
  resume: true       # è·³è¿‡å·²æœ‰ç­”æ¡ˆçš„è¡Œ
  save_every: 5      # æ¯å¤„ç† N è¡Œä¿å­˜ä¸€æ¬¡ï¼ˆé˜²ä¸­æ–­ï¼‰

# -----------------------------------------------------
# ğŸ–¥ï¸ ç³»ç»Ÿé…ç½®
# -----------------------------------------------------
system:
  # æ—¥å¿—çº§åˆ«
  log_level: "INFO"
  
  # å‘é‡æ•°æ®åº“
  vector_db:
    persist_dir: ".cache/chroma_db"
    force_rebuild: false  # true = æ¯æ¬¡é‡å»ºç´¢å¼•
  
  # ç¼“å­˜
  cache:
    enabled: true
    dir: ".cache/"
